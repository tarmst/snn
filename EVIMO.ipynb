{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c61e32fa-4662-4c2f-8820-130bf9fa13be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tonic\n",
    "import tonic.transforms as transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from tonic.dataset import Dataset\n",
    "from typing import Callable, Optional\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.ops import masks_to_boxes\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import matplotlib.patches as patches\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b30097a0-45a9-41a5-92c4-18344bedafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./mnist_sg_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b519d7-7625-47ad-bf9e-4bfea280d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import snn_utils\n",
    "import base_model\n",
    "import lenet_decolle_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4260d3-1022-4b5c-816d-d15b6322f461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.cuda.device at 0x7f7fc59b2fb0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.cuda.device(i) for i in range(torch.cuda.device_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2440213f-255c-496c-8cc3-e3167d74f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"/media/user/EVIMO/raw/imo/eval/scene15_dyn_test_01/left_camera/ground_truth_000000\"\n",
    "sensor_size = [640, 480, 2]\n",
    "batch_size = 6\n",
    "num_bins_per_frame = 4\n",
    "test_num_bins_per_frame = 8\n",
    "framerate = 200\n",
    "device = 'cuda'\n",
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eee4657b-59c4-4dd1-8f51-d9492c27f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EVIMO(Dataset):\n",
    "    def __init__(self,\n",
    "                 dir: str,\n",
    "                 item_to_find: int,\n",
    "                 num_bins_per_frame: int,\n",
    "                 #start_idx: int,\n",
    "                ):\n",
    "        self.dir = dir\n",
    "        self.item_to_find = item_to_find\n",
    "        self.num_bins_per_frame = num_bins_per_frame\n",
    "        self.length = np.load(self.dir + \"/length.npy\")\n",
    "        #print(self.length)\n",
    "        #self.start_idx = start_idx\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = np.load(self.dir + \"/\" + str(index) + \".npy\", allow_pickle=True).tolist()\n",
    "        if self.item_to_find in item[\"objs_in_mask\"]:\n",
    "            target = np.asarray([0, 1])\n",
    "        else:\n",
    "            target = np.asarray([1, 0])\n",
    "\n",
    "        target = np.tile(target, (self.num_bins_per_frame, 1))\n",
    "\n",
    "        return {\"data\": torch.from_numpy(item[\"binned_events\"]), \"target\": torch.from_numpy(target)}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.length # - self.start_idx\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3924fba9-fb6a-4b62-bba3-05cefb5b6d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __getitem__(self, index):\n",
    "        if index < 512:\n",
    "            return {\"data\": torch.zeros([test_num_bins_per_frame, 2, 480, 640]), \"target\": np.tile(torch.from_numpy(np.array([1, 0])), (test_num_bins_per_frame,1))}\n",
    "        else:\n",
    "            return {\"data\": torch.ones([test_num_bins_per_frame, 2, 480, 640]), \"target\": np.tile(torch.from_numpy(np.array([0, 1])), (test_num_bins_per_frame,1))}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d84cf6b1-6549-48cb-adbb-7511b28d4bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset()\n",
    "tonic_dataset = EVIMO(dir=\"./data/EVIMO/left_cam/scene13_test5\", item_to_find=23, num_bins_per_frame=num_bins_per_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1da311e-c2cc-4297-8f82-4c60c82ce015",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ones = 0\n",
    "targ_set = set()\n",
    "\n",
    "for i in range(0, len(tonic_dataset)):\n",
    "    item = tonic_dataset[i]\n",
    "    answers = np.unique(item[\"target\"].argmax()).tolist()\n",
    "    for a in answers:\n",
    "        if a == 1:\n",
    "            num_ones += 1\n",
    "        targ_set.add(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac698a22-7570-4b2e-81cf-0b6d506e90e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ebd06b2-9fd0-4035-821e-62b5a88e5ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5031446540880503"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ones / len(tonic_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7fa9a80-586b-4ace-b999-c9d0cd987723",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_trainloader = DataLoader(tonic_dataset, batch_size=batch_size, shuffle=False) # collate_fn=tonic.collation.PadTensors(),\n",
    "test_trainloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7fa7d1e-a4e4-461a-90c3-4b663b07f1bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i_batch, sample_batched in enumerate(trainloader):\n",
    "#    print(i_batch, sample_batched['data'].size(), sample_batched['target'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f582f111-a1af-4ee6-adeb-b4bd1f13f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "datait = iter(batched_trainloader)\n",
    "batched_data = next(datait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45aaaff3-d489-42d5-9ecb-0489e2a53c0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4, 2, 480, 640])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36bcc119-507e-4816-8847-991642b22308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1]],\n",
       "\n",
       "        [[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1]],\n",
       "\n",
       "        [[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1]],\n",
       "\n",
       "        [[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_data['target'].transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6523f57-d1d4-4fd6-ac13-240c4791c9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_data['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f64c126-c5ce-4e81-b2cd-52a243e07cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1]],\n",
       "\n",
       "        [[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1]],\n",
       "\n",
       "        [[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1]],\n",
       "\n",
       "        [[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1]],\n",
       "\n",
       "        [[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1]],\n",
       "\n",
       "        [[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04068d16-f2c8-4e60-a9c9-dca6377f1b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "datait = iter(test_trainloader)\n",
    "batched_data = next(datait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f080062b-e626-47cf-bf8f-118ff4cdee4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 8, 2, 480, 640])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "321a0824-3a31-4af3-b745-e4c5f7d5eee1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER SIZE: 2421888\n",
      "STDV: 0.00032128686926965593\n",
      "LAYER SIZE: 68096\n",
      "STDV: 0.0019160604358905182\n",
      "LAYER SIZE: 64\n",
      "STDV: 0.0625\n",
      "torch.Size([6, 4, 2, 480, 640])\n"
     ]
    }
   ],
   "source": [
    "item = next(iter(batched_trainloader))\n",
    "data = item['data']\n",
    "target = item['target']\n",
    "\n",
    "loss = torch.nn.SmoothL1Loss()\n",
    "\n",
    "def decolle_loss(r, s, tgt):\n",
    "    loss_tv = 0\n",
    "    for i in range(len(r)):\n",
    "        if r[i].shape != tgt.shape:\n",
    "            print(f\"Loss Readout shape : {r[i].shape}\")\n",
    "            print(f\"Loss Target shape : {tgt.shape}\")\n",
    "        loss_tv += loss(r[i],tgt) \n",
    "    return loss_tv\n",
    "\n",
    "\n",
    "convnet_sg = lenet_decolle_model.LenetDECOLLE(out_channels=2,\n",
    "                    Nhid=[128, 256], #Number of convolution channels\n",
    "                    Mhid=[64],\n",
    "                    kernel_size=[8, 16],\n",
    "                    pool_size=[4, 8],\n",
    "                    input_shape=[2, 480, 640],  # data.shape[1:],\n",
    "                    alpha=[.95],\n",
    "                    alpharp=[.65],\n",
    "                    beta=[.92],\n",
    "                    num_conv_layers=2,\n",
    "                    num_mlp_layers=1,\n",
    "                    lc_ampl=0.5).to(device)\n",
    "\n",
    "#net = lenet_decolle_model.LenetDECOLLE(Nhid=[1,8],Mhid=[32,64],out_channels=2, input_shape=[2, 480, 640]).to(device)\n",
    "\n",
    "convnet_sg\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data_d = data.to(device)\n",
    "target_d = target.to(device)\n",
    "convnet_sg.init_parameters(data_d) # Modifies readout dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e26c9fd9-1b04-4d7d-b4fc-a059bac83ce8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4, 2, 480, 640])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0916f05f-2752-4d2d-bdcb-427f9ac049b9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_d.transpose(0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f839e066-2097-48bc-ab39-baa0e62f7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "553f03ca-b3ef-4c1c-9662-52a31ac76679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7408e907-b4a4-4eca-8a5d-e3943bd68333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88e62e65-490a-4c02-b2ac-f5070f4280fe",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bd4469f9d747d6b92b0c1adcce7f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 0 Loss tensor(4.5921, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0491843ef334fdeaa1809c6c0e5165d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 1 Loss tensor(4.5035, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b423dfed1b04c1f9a348bae18f36a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 2 Loss tensor(4.2372, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e095166b6a44002be96d17c89a84d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 3 Loss tensor(4.5686, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef69669be1354e6a8bcd7787d086f320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 4 Loss tensor(4.0304, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac590f0a528841a5bbba854b8d554451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 5 Loss tensor(4.3828, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc62f925c0247fd83c5796b6aae162e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 6 Loss tensor(3.8221, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd359114220345b08135cab9b9e0837b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 7 Loss tensor(4.4965, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d0098a48174353a3afd27a90c5d650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 8 Loss tensor(4.3368, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da95c35f560a4333a2fb3b15ef5bde71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 9 Loss tensor(4.6912, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef68f65829f436ebf08ba1125d9f547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 10 Loss tensor(4.0823, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef7f2375d074a3bbf34b585010f4907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 11 Loss tensor(4.6655, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c844298ba70d4b8e80f657271f22ec81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 12 Loss tensor(4.0685, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b00aaa0a7014481ac52411e3dbefda0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 13 Loss tensor(4.3823, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e13f67705eb449b9c0159d4690ce114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 14 Loss tensor(4.3957, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6c653290e84041b141396574c6f581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 15 Loss tensor(4.5562, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74ddce8ac5d494c83e6b0043ba6d101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 16 Loss tensor(4.1108, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86253964056c4ed0bc00a147c9121131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 17 Loss tensor(4.4084, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4616689897ee4032b2574a466c80995c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 18 Loss tensor(4.3916, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ddbc51f20d482b91df4fec3dbd277d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error tensor(0.4969)\n",
      "Training accuracy tensor(0.5031)\n",
      "Epoch 19 Loss tensor(3.8889, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "opt_conv = torch.optim.Adamax(convnet_sg.get_trainable_parameters(), lr=1e-3, betas=[0., .95])\n",
    "\n",
    "# Their data_d is T, batchsize, pol, x, y (16, 4, 1, 28, 28)\n",
    "# Mine is batchsize, T, pol, x,y\n",
    "\n",
    "for e in range(epochs):        \n",
    "    error = []\n",
    "    accuracy=[]\n",
    "    for item in tqdm(iter(batched_trainloader), desc=f\"Epoch {e}\"):\n",
    "        data = item['data']\n",
    "        label = item['target'] #.transpose(0, 1)\n",
    "\n",
    "        #if label.shape[0] != 4:\n",
    "            #print(f\"last entry\")\n",
    "            #break\n",
    "        \n",
    "        convnet_sg.train()\n",
    "        loss_hist = 0\n",
    "        data_d = data.to(device)\n",
    "        label_d = label.to(device)\n",
    "        #print(len(convnet_sg))\n",
    "        convnet_sg.init(data_d, burnin=3)\n",
    "        readout = 0\n",
    "\n",
    "        #print(label_d.shape)\n",
    "        #print(label_d)\n",
    "\n",
    "        data_d = data_d.transpose(0, 1)\n",
    "        label_d = label_d.transpose(0, 1)\n",
    "        \n",
    "        #print(label_d.shape)\n",
    "        #print(label_d)\n",
    "        \n",
    "        for n in range(num_bins_per_frame):\n",
    "            # CORRECT: Data shape: torch.Size([4, 2, 480, 640]), overall: torch.Size([8, 4, 2, 480, 640])\n",
    "            #print(f\"Data shape: {data_d[n].shape}, overall: {data_d.shape}\")\n",
    "            #print(data_d[n])\n",
    "            \n",
    "            st, rt, ut = convnet_sg.forward(data_d[n])\n",
    "            #print(\"Readout\")\n",
    "            #print(len(rt), rt[0].shape, rt[1].shape, rt[2].shape)\n",
    "            #print(rt[-1].shape)\n",
    "\n",
    "            # CORRECT: Label shape: torch.Size([4, 2]), overall: torch.Size([8, 4, 2])\n",
    "            #print(f\"Label shape: {label_d[n].shape}, overall: {label_d.shape}\")\n",
    "            #print(label_d[n].shape, label_d[n])\n",
    "            \n",
    "            #print(label_d)\n",
    "            #break\n",
    "            loss_tv = decolle_loss(rt, st, label_d[n])\n",
    "            \n",
    "            loss_tv.backward()\n",
    "            opt_conv.step()\n",
    "            opt_conv.zero_grad()\n",
    "            loss_hist += loss_tv\n",
    "            readout += rt[-1]\n",
    "\n",
    "        #print(f\"Readout: {readout}\")\n",
    "        #error += (readout.argmax(axis=1)!=label_d.argmax(axis=1)).float()\n",
    "        #accuracy+=(readout.argmax(axis=1)==label_d.argmax(axis=1)).float()\n",
    "\n",
    "        # SEEM CORRECT\n",
    "        argmaxed_readout = readout.argmax(axis=1)\n",
    "        #print(\"argmaxeds\")\n",
    "        #print(argmaxed_readout)\n",
    "        #print(label_d)\n",
    "        #print(label_d[-1])\n",
    "        #print(label_d.argmax(axis=1))\n",
    "        argmaxed_label = label_d[-1].argmax(axis=1)\n",
    "        #print(argmaxed_label)\n",
    "        #break\n",
    "        #print(\"argmaxed readout\")\n",
    "        #print(argmaxed_readout)\n",
    "        #print(\"argmaxed label\")\n",
    "        #print(argmaxed_label)\n",
    "        error += (argmaxed_readout!=argmaxed_label).float()\n",
    "        accuracy+=(argmaxed_readout==argmaxed_label).float()\n",
    "        #print(f\"Accuracy: {accuracy}\")\n",
    "        #break\n",
    "        \n",
    "    print('Training Error', torch.mean(torch.Tensor(error)).data)\n",
    "    print('Training accuracy', torch.mean(torch.Tensor(accuracy)).data)     \n",
    "    print('Epoch', e, 'Loss', loss_hist.data)\n",
    "    PATH = './EVIMO_class_cnn.pth'  \n",
    "    torch.save(convnet_sg.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9961fd94-fc2f-41db-aab0-25a5539903c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loss_tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "848ee114-ef61-4a57-9d90-f28f99147570",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Error tensor(nan)\n",
      "Testing accuracy tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "accuracy=[]\n",
    "y_pred = []\n",
    "y_true = []\n",
    "#convnet_sg.requires_init = True\n",
    "for item in iter(batched_trainloader):\n",
    "    #print(\"Item\")\n",
    "    #print(item)\n",
    "    data = item['data']\n",
    "    label = item['target']\n",
    "    if label.shape[0] != 4:\n",
    "        #print(f\"last entry: {label}\")\n",
    "        break\n",
    "\n",
    "    #print(\"earliest label\")\n",
    "    #print(label)\n",
    "    #print(label.shape)\n",
    "\n",
    "    \n",
    "    loss_hist = 0\n",
    "    data_d = data.to(device)\n",
    "    label_d = label.to(device)\n",
    "    print(f\"data_d shape: {data_d.shape}\")\n",
    "    print(f\"data_d_tranpose shape: {data_d.transpose(0,1).shape}\")\n",
    "    print(f\"Len convnet: {len(convnet_sg)}\")\n",
    "    print(f\"data init shape: {data_d.transpose(0,1)[:, 0, :, :].shape}\")\n",
    "    print(f\"Test data shape: {data_d[0].shape}\")\n",
    "    \n",
    "    convnet_sg.init_evimo(data_d)\n",
    "    readout = 0\n",
    "    with torch.no_grad():\n",
    "        #for i in range(0, len(data_d)):\n",
    "        #d = data_d[i:i+1]\n",
    "        \n",
    "        #print(d.shape)\n",
    "        \n",
    "        st, rt, ut = convnet_sg.forward(data_d)\n",
    "\n",
    "        \n",
    "        \n",
    "        print(f\"Label shape: {label_d.shape}\")\n",
    "        print(\"Readout\")\n",
    "        print(rt)\n",
    "        print(rt[0].shape)\n",
    "\n",
    "        #print(\"labels\")\n",
    "        #print(label_d)\n",
    "        #print(label_d.shape)\n",
    "        \n",
    "        \n",
    "        loss_tv = decolle_loss(rt, st, label_d)\n",
    "        \n",
    "        \n",
    "        loss_hist += loss_tv\n",
    "        readout += rt[-1]\n",
    "        print(f\"Readout: {readout}\")\n",
    "        output = (readout.argmax(axis=1)).data.cpu().numpy()\n",
    "        print(f\"Output: {output}\")\n",
    "        y_pred.extend(output)\n",
    "        #labels = label_d.argmax(axis=1)\n",
    "        print(f\"Labels: {label_d}\")\n",
    "        labels = (label_d.argmax(axis=1)).data.cpu().numpy()\n",
    "        print(f\"Labels: {labels}\")\n",
    "        y_true.extend(labels)\n",
    "        accuracy+=(readout.argmax(axis=1)==label_d.argmax(axis=1)).float()\n",
    "        error += (readout.argmax(axis=1)!=label_d.argmax(axis=1)).float()\n",
    "        break\n",
    "        \n",
    "print('Testing Error', torch.mean(torch.Tensor(error)).data)\n",
    "print('Testing accuracy', torch.mean(torch.Tensor(accuracy)).data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c14e8c82-256e-490b-b93b-7f5ac7d7493d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1b2bc5a-e41a-4848-b296-e23b3c12b4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nconvnet_sg = lenet_decolle_model.LenetDECOLLE( out_channels=2,\\n                    Nhid=[16,32], #Number of convolution channels\\n                    Mhid=[64],\\n                    kernel_size=[7],\\n                    pool_size=[2,2],\\n                    input_shape=[2, 480, 640],  # data.shape[1:],\\n                    alpha=[.95],\\n                    alpharp=[.65],\\n                    beta=[.92],\\n                    num_conv_layers=2,\\n                    num_mlp_layers=1,\\n                    lc_ampl=.5).to(device)\\n\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "convnet_sg = lenet_decolle_model.LenetDECOLLE( out_channels=2,\n",
    "                    Nhid=[16,32], #Number of convolution channels\n",
    "                    Mhid=[64],\n",
    "                    kernel_size=[7],\n",
    "                    pool_size=[2,2],\n",
    "                    input_shape=[2, 480, 640],  # data.shape[1:],\n",
    "                    alpha=[.95],\n",
    "                    alpharp=[.65],\n",
    "                    beta=[.92],\n",
    "                    num_conv_layers=2,\n",
    "                    num_mlp_layers=1,\n",
    "                    lc_ampl=.5).to(device)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "685f938a-2daa-4af3-98e2-ddf8be8f91b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER SIZE: 1228800\n",
      "STDV: 0.00045105489780439506\n",
      "LAYER SIZE: 614400\n",
      "STDV: 0.000637887953849786\n",
      "LAYER SIZE: 64\n",
      "STDV: 0.0625\n",
      "torch.Size([1, 2, 480, 640])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "net = lenet_decolle_model.LenetDECOLLE(Nhid=[16,32],Mhid=[64],out_channels=2, pool_size=[2,2], num_conv_layers=2, num_mlp_layers=1, lc_ampl=.5, input_shape=[2, 480, 640])\n",
    "d = torch.zeros([1, 2, 480, 640])\n",
    "print(d.shape)\n",
    "st, rt, ut = net.forward(d)\n",
    "print(rt[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f5490-a0b7-4311-80af-37368d824a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec08fa76-8a93-42a9-91b8-05eca9db7f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.0234, 0.1313]], grad_fn=<AddmmBackward0>), tensor([[0.1324, 0.1237]], grad_fn=<AddmmBackward0>), tensor([[ 0.1712, -0.0014]], grad_fn=<AddmmBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "213e3376-231b-4b64-a521-57b2ca6944f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.zeros([1, 2])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e406213-5c03-4e68-bc2f-e8fe4a8c4e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_tv = decolle_loss(rt, st, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bffc1a-f0f1-44b2-b386-620613fa93ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79139852-ca64-4c41-8367-55d7334f4a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
