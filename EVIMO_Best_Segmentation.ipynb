{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152c8f5d-1c50-4837-a35f-fc0a8bb58ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tonic\n",
    "import tonic.transforms as transforms\n",
    "from torchvision import transforms as tt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from tonic.dataset import Dataset\n",
    "from typing import Callable, Optional\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.ops import masks_to_boxes\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from typing import Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "from statistics import mean\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch import utils\n",
    "from snntorch import functional as SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ded033c-bc1f-44c7-b17e-05096e4e8446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't change unless also changed in EVIMO saving\n",
    "num_bins_per_frame = 8 \n",
    "framerate = 200\n",
    "\n",
    "# Standardized sizes, from EVIMO recording\n",
    "sensor_size = [640, 480, 2]\n",
    "input_size=(480, 640)\n",
    "\n",
    "beta = 0.9\n",
    "\n",
    "batch_size = 4\n",
    "num_epochs = 1\n",
    "\n",
    "num_classes = 25\n",
    "\n",
    "output_size= (480, 640) #(30, 40) # Can be changed\n",
    "\n",
    "dtype=torch.float\n",
    "#device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6073ee46-bf1c-4fd8-8fb6-d762f32e4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EVIMOMask(Dataset):\n",
    "    def __init__(self,\n",
    "                 dirs: list,\n",
    "                 num_bins_per_frame: int,\n",
    "                 output_size: Tuple,\n",
    "                ):\n",
    "        self.dirs = dirs\n",
    "        self.num_bins_per_frame = num_bins_per_frame\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.length = 0\n",
    "        self.lengths = []\n",
    "        for dir in self.dirs:\n",
    "            curr_len = np.load(dir + \"/length.npy\")\n",
    "            self.length += curr_len\n",
    "            self.lengths.append(curr_len)\n",
    "\n",
    "    def find_num_classes():\n",
    "        self.num_classes = 0\n",
    "        self.classes = torch.empty((1, ))\n",
    "        for idx in range(0, len(self)):\n",
    "            dir, index = self.get_dir_index(idx)\n",
    "\n",
    "            item = np.load(dir + \"/\" + str(index) + \".npy\", allow_pickle=True).tolist()\n",
    "            mask = torch.from_numpy(np.asarray([item[\"mask\"]])).to(torch.int64)\n",
    "\n",
    "            classes = torch.unique(mask, sorted=False)\n",
    "            self.classes = torch.cat((self.classes, classes), dim=0)\n",
    "\n",
    "        self.classes = torch.unique(self.classes)\n",
    "        self.num_classes = int(self.classes.max()) + 1\n",
    "            \n",
    "\n",
    "    def get_dir_index(self, index):\n",
    "        curr_idx_sum = 0\n",
    "        for i, length in enumerate(self.lengths):\n",
    "            #print(index, length, curr_idx_sum)\n",
    "            if curr_idx_sum <= index < curr_idx_sum + length:\n",
    "                dir = self.dirs[i]\n",
    "                index -= curr_idx_sum\n",
    "                break\n",
    "            curr_idx_sum += length\n",
    "                \n",
    "\n",
    "        return dir, index\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        dir, index = self.get_dir_index(index)\n",
    "        \n",
    "        item = np.load(dir + \"/\" + str(index) + \".npy\", allow_pickle=True).tolist()\n",
    "\n",
    "        events = np.asarray(item[\"events\"])\n",
    "\n",
    "        frame_transform = transforms.Compose([# transforms.Denoise(filter_time=0.01),\n",
    "                                       transforms.ToVoxelGrid(sensor_size=sensor_size,\n",
    "                                                          n_time_bins=self.num_bins_per_frame)\n",
    "                                      ])\n",
    "\n",
    "        events = frame_transform(events)\n",
    "\n",
    "        mask = torch.from_numpy(np.asarray([item[\"mask\"]])).to(torch.int64)\n",
    "\n",
    "        one_hot_mask = torch.nn.functional.one_hot(mask, num_classes=num_classes).transpose(1, 3).transpose(2, 3) # Conversion into Batch, Channels, H, W\n",
    "\n",
    "        # Downsize the mask.\n",
    "        resized_mask = tt.functional.resize(one_hot_mask, self.output_size, antialias=True)\n",
    "        \n",
    "        return torch.from_numpy(events).to(torch.float), resized_mask.squeeze()\n",
    "\n",
    "    def get_original_mask(self, index):\n",
    "        dir, index = self.get_dir_index(index)\n",
    "        \n",
    "        item = np.load(dir + \"/\" + str(index) + \".npy\", allow_pickle=True).tolist()\n",
    "        mask = torch.from_numpy(np.asarray([item[\"mask\"]])).to(torch.int64)\n",
    "        return mask\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.length # - self.start_idx\n",
    "\n",
    "    # def get_item(self, index):\n",
    "    #     item = np.load(self.dir + \"/\" + str(index) + \".npy\", allow_pickle=True).tolist()\n",
    "    #     return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b0f6568-9b46-4b0a-88c1-e746ec1616ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [\"./data/EVIMO/left_cam/scene13_test5\",\n",
    "       \"./data/EVIMO/left_cam/scene14_test3\",\n",
    "       \"./data/EVIMO/left_cam/scene15_test1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e2ef28-8e1a-499b-beae-3226bc221593",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EVIMOMask(dirs=dirs, output_size=output_size, num_bins_per_frame=num_bins_per_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6088f14-0f64-48a4-8658-d21db17598d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2181"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d036a62b-05d8-4d25-9e19-11e880deac86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 480, 640]), torch.Size([25, 480, 640]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins, mask = dataset[2100]\n",
    "bins.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83bc1031-9f35-49f3-9499-982400095109",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.conv2 = nn.Conv2d(4, 4, kernel_size=5, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(4, 8, kernel_size=2, stride=2)\n",
    "        #self.unpool1 = nn.MaxUnpool2d(2)\n",
    "        #nn.Flatten(),\n",
    "        ##nn.Linear(64*4*4, 10),\n",
    "        self.lif3 = snn.Leaky(beta=beta)\n",
    "        self.upconv2 = nn.ConvTranspose2d(8, num_classes, kernel_size=2, stride=2)\n",
    "        #self.unpool2 = nn.MaxUnpool2d(2)\n",
    "        self.lif4 = snn.Leaky(beta=beta, output=True)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "        mem4 = self.lif4.init_leaky()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        spk1, mem1 = self.lif1(x, mem1)\n",
    "        x = self.pool2(self.conv2(spk1))\n",
    "        spk2, mem2 = self.lif2(x, mem2)\n",
    "\n",
    "        #print(spk2.shape)\n",
    "        x = self.upconv1(spk2)\n",
    "        #print(x.shape)\n",
    "        spk3, mem3 = self.lif3(x, mem3)\n",
    "\n",
    "        x = self.upconv2(spk3)\n",
    "        spk4, mem4 = self.lif4(x, mem4)\n",
    "\n",
    "        return spk4, mem4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d970099-1734-4152-bd8e-033777b462c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4334c814-072a-44f0-bf48-d36fa88436c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(data):\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "    utils.reset(model)  # resets hidden states for all LIF neurons in net\n",
    "    \n",
    "    data = data.transpose(0, 1) # num_steps, batch_size, C, H, W\n",
    "    \n",
    "    for step in range(num_bins_per_frame):\n",
    "      spk_out, mem_out = model(data[step])\n",
    "      spk_rec.append(spk_out)\n",
    "      mem_rec.append(mem_out)\n",
    "\n",
    "    return torch.stack(spk_rec), torch.stack(mem_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24183957-73b5-4ef1-9cd2-bcf6151a0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_rec, mem_rec = model(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9876aac-ded8-4844-8cb3-8b99e6127c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 25, 480, 640])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spk_rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37143eeb-b994-4175-9076-e83eb89561f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = SF.ce_temporal_loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "521f560b-8602-400a-8cc6-b1058297eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5087beb-9b7a-4a8a-96b4-cd36745f8f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1736e2efda194b96ae759029c2a1fb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/546 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_batch = tqdm(iter(trainloader), desc=f\"Epoch {epoch}\")\n",
    "    for data, masks in train_batch:\n",
    "        data = data.to(device).to(torch.float) # Data currently in batch_size, num_steps, Channels, H, W\n",
    "        masks = masks.to(device).to(torch.float)\n",
    "\n",
    "        model.train()\n",
    "        spk_rec, _ = forward_pass(data)\n",
    "        loss_val = loss_fn(spk_rec, masks)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb119b21-3bd4-4097-a757-e975cc7ef2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
