{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "uSGZ6cdmpknm",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"400\">](https://github.com/jeshraghian/snntorch/)\n",
    "\n",
    "\n",
    "# snnTorch - Training Spiking Neural Networks with snnTorch\n",
    "## Tutorial 5\n",
    "### By Jason K. Eshraghian (www.ncg.ucsc.edu)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/master/examples/tutorial_6_CNN.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "\n",
    "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub-Mark-Light-120px-plus.png?raw=true' width=\"28\">](https://github.com/jeshraghian/snntorch/) [<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub_Logo_White.png?raw=true' width=\"80\">](https://github.com/jeshraghian/snntorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rugeYYiqsrlc"
   },
   "source": [
    "The snnTorch tutorial series is based on the following paper. If you find these resources or code useful in your work, please consider citing the following source:\n",
    "\n",
    "> <cite> [Jason K. Eshraghian, Max Ward, Emre Neftci, Xinxin Wang, Gregor Lenz, Girish Dwivedi, Mohammed Bennamoun, Doo Seok Jeong, and Wei D. Lu. \"Training Spiking Neural Networks Using Lessons From Deep Learning\". Proceedings of the IEEE, 111(9) September 2023.](https://ieeexplore.ieee.org/abstract/document/10242251) </cite>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ymi3sqJg28OQ"
   },
   "source": [
    "# Introduction\n",
    "In this tutorial, you will:\n",
    "* Learn how spiking neurons are implemented as a recurrent network\n",
    "* Understand backpropagation through time, and the associated challenges in SNNs such as the non-differentiability of spikes\n",
    "* Train a fully-connected network on the static MNIST dataset\n",
    "\n",
    "<!-- * Implement various backprop strategies:\n",
    "  * Backpropagation Through Time\n",
    "  * Truncated-Backpropagation Through Time\n",
    "  * Real-Time Recurrent Learning -->\n",
    "\n",
    ">Part of this tutorial was inspired by Friedemann Zenke's extensive work on SNNs. Check out his repo on surrogate gradients [here](https://github.com/fzenke/spytorch), and a favourite paper of mine: E. O. Neftci, H. Mostafa, F. Zenke, [Surrogate Gradient Learning in Spiking Neural Networks: Bringing the Power of Gradient-based optimization to spiking neural networks.](https://ieeexplore.ieee.org/document/8891809) IEEE Signal Processing Magazine 36, 51–63.\n",
    "\n",
    "At the end of the tutorial, a basic supervised learning algorithm will be implemented. We will use the original static MNIST dataset and train a multi-layer fully-connected spiking neural network using gradient descent to perform image classification.\n",
    "\n",
    "If running in Google Colab:\n",
    "* You may connect to GPU by checking `Runtime` > `Change runtime type` > `Hardware accelerator: GPU`\n",
    "* Next, install the latest PyPi distribution of snnTorch by clicking into the following cell and pressing `Shift+Enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5tn_wUlopkon",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install snntorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QXZ6Tuqc9Q-l"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gt2xMbLY9dVE"
   },
   "source": [
    "# 1. A Recurrent Representation of SNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7haBG7nA_TC"
   },
   "source": [
    "In Tutorial 3, we derived a recursive representation of a leaky integrate-and-fire (LIF) neuron:\n",
    "\n",
    "$$U[t+1] = \\underbrace{\\beta U[t]}_\\text{decay} + \\underbrace{WX[t+1]}_\\text{input} - \\underbrace{R[t]}_\\text{reset} \\tag{1}$$\n",
    "\n",
    "where the input synaptic current is interpreted as $I_{\\rm in}[t] = WX[t]$, and $X[t]$ may be some arbitrary input of spikes, a step/time-varying voltage, or unweighted step/time-varying current. Spiking is represented with the following equation, where if the membrane potential exceeds the threshold, a spike is emitted:\n",
    "\n",
    "$$S[t] = \\begin{cases} 1, &\\text{if}~U[t] > U_{\\rm thr} \\\\\n",
    "0, &\\text{otherwise}\\end{cases} \\tag{2}$$\n",
    "\n",
    "This formulation of a spiking neuron in a discrete, recursive form is almost perfectly poised to take advantage of the developments in training recurrent neural networks (RNNs) and sequence-based models. This is illustrated using an *implicit* recurrent connection for the decay of the membrane potential, and is distinguished from *explicit* recurrence where the output spike $S_{\\rm out}$ is fed back to the input. In the figure below, the connection weighted by $-U_{\\rm thr}$ represents the reset mechanism $R[t]$.\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial5/unrolled_2.png?raw=true' width=\"800\">\n",
    "</center>\n",
    "\n",
    "The benefit of an unrolled graph is that it provides an explicit description of how computations are performed. The process of unfolding illustrates the flow of information forward in time (from left to right) to compute outputs and losses, and backward in time to compute gradients. The more time steps that are simulated, the deeper the graph becomes.\n",
    "\n",
    "Conventional RNNs treat $\\beta$ as a learnable parameter. This is also possible for SNNs, though by default, they are treated as hyperparameters. This replaces the vanishing and exploding gradient problems with a hyperparameter search. A future tutorial will describe how to make $\\beta$ a learnable parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wgzf83HE2BeB"
   },
   "source": [
    "# 2. The Non-Differentiability of Spikes\n",
    "## 2.1 Training Using the Backprop Algorithm\n",
    "\n",
    "An alternative way to represent the relationship between $S$ and $U$ in $(2)$ is:\n",
    "\n",
    "$$S[t] = \\Theta(U[t] - U_{\\rm thr}) \\tag{3}$$\n",
    "\n",
    "where $\\Theta(\\cdot)$ is the Heaviside step function:\n",
    "\n",
    "<center>\n",
    "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial3/3_2_spike_descrip.png?raw=true' width=\"600\">\n",
    "</center>\n",
    "\n",
    "Training a network in this form poses some serious challenges. Consider a single, isolated time step of the computational graph from the previous figure titled *\"Recurrent representation of spiking neurons\"*, as shown in the *forward pass* below:\n",
    "\n",
    "<center>\n",
    "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial5/non-diff.png?raw=true' width=\"400\">\n",
    "</center>\n",
    "\n",
    "The goal is to train the network using the gradient of the loss with respect to the weights, such that the weights are updated to minimize the loss. The backpropagation algorithm achieves this using the chain rule:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial W} =\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial S}\n",
    "\\underbrace{\\frac{\\partial S}{\\partial U}}_{\\{0, \\infty\\}}\n",
    "\\frac{\\partial U}{\\partial I}\\\n",
    "\\frac{\\partial I}{\\partial W}\\ \\tag{4}$$\n",
    "\n",
    "From $(1)$, $\\partial I/\\partial W=X$, and $\\partial U/\\partial I=1$. While we have not yet defined a loss function, we can assume $\\partial \\mathcal{L}/\\partial S$ has an analytical solution, in a similar form to the cross-entropy or mean-square error loss (more on that shortly).\n",
    "\n",
    "However, the term that we are going to grapple with is $\\partial S/\\partial U$. The derivative of the Heaviside step function from $(3)$ is the Dirac Delta function, which evaluates to 0 everywhere, except at the threshold $U_{\\rm thr} = \\theta$, where it tends to infinity. This means the gradient will almost always be nulled to zero (or saturated if $U$ sits precisely at the threshold), and no learning can take place. This is known as the **dead neuron problem**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVrM7nLOMvgx"
   },
   "source": [
    "## 2.2 Overcoming the Dead Neuron Problem\n",
    "\n",
    "The most common way to address the dead neuron problem is to keep the Heaviside function as it is during the forward pass, but swap the derivative term $\\partial S/\\partial U$ for something that does not kill the learning process during the backward pass, which will be denoted $\\partial \\tilde{S}/\\partial U$. This might sound odd, but it turns out that neural networks are quite robust to such approximations. This is commonly known as the *surrogate gradient* approach.\n",
    "\n",
    "A variety of options exist to using surrogate gradients, and we will dive into more detail on these methods in [Tutorial 6](https://snntorch.readthedocs.io/en/latest/tutorials/index.html). The default method in snnTorch (as of v0.6.0) is to smooth the Heaviside function with the arctangent function. The backward-pass derivative used is:\n",
    "\n",
    "$$ \\frac{\\partial \\tilde{S}}{\\partial U} \\leftarrow \\frac{1}{\\pi}\\frac{1}{(1+[U\\pi]^2)} \\tag{5}$$\n",
    "\n",
    "where the left arrow denotes substitution.\n",
    "\n",
    "The same neuron model described in  $(1)-(2)$ (a.k.a., `snn.Leaky` neuron from Tutorial 3) is implemented in PyTorch below. Don't worry if you don't understand this. This will be condensed into one line of code using snnTorch in a moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mfJUm-6T8aG2"
   },
   "outputs": [],
   "source": [
    "# Leaky neuron model, overriding the backward pass with a custom function\n",
    "class LeakySurrogate(nn.Module):\n",
    "  def __init__(self, beta, threshold=1.0):\n",
    "      super(LeakySurrogate, self).__init__()\n",
    "\n",
    "      # initialize decay rate beta and threshold\n",
    "      self.beta = beta\n",
    "      self.threshold = threshold\n",
    "      self.spike_gradient = self.ATan.apply\n",
    "\n",
    "  # the forward function is called each time we call Leaky\n",
    "  def forward(self, input_, mem):\n",
    "    spk = self.spike_gradient((mem-self.threshold))  # call the Heaviside function\n",
    "    reset = (self.beta * spk * self.threshold).detach() # remove reset from computational graph\n",
    "    mem = self.beta * mem + input_ - reset # Eq (1)\n",
    "    return spk, mem\n",
    "\n",
    "  # Forward pass: Heaviside function\n",
    "  # Backward pass: Override Dirac Delta with the ArcTan function\n",
    "  @staticmethod\n",
    "  class ATan(torch.autograd.Function):\n",
    "      @staticmethod\n",
    "      def forward(ctx, mem):\n",
    "          spk = (mem > 0).float() # Heaviside on the forward pass: Eq(2)\n",
    "          ctx.save_for_backward(mem)  # store the membrane for use in the backward pass\n",
    "          return spk\n",
    "\n",
    "      @staticmethod\n",
    "      def backward(ctx, grad_output):\n",
    "          (mem,) = ctx.saved_tensors  # retrieve the membrane potential\n",
    "          grad = 1 / (1 + (np.pi * mem).pow_(2)) * grad_output # Eqn 5\n",
    "          return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zkc1Mmp97OX"
   },
   "source": [
    "Note that the reset mechanism is detached from the computational graph, as the surrogate gradient should only be applied to $\\partial S/\\partial U$, and not $\\partial R/\\partial U$.\n",
    "\n",
    "The above neuron is instantiated using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EV3lU6soOnW6"
   },
   "outputs": [],
   "source": [
    "lif1 = LeakySurrogate(beta=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StklvL_gPns1"
   },
   "source": [
    "This neuron can be simulated using a for-loop, just as in previous tutorials, while PyTorch's automatic differentation (autodiff) mechanism keeps track of the gradient in the background.\n",
    "\n",
    "Alternatively, the same thing can be accomplished by calling the `snn.Leaky` neuron.\n",
    "In fact, every time you call any neuron model from snnTorch, the *ATan* surrogate gradient is applied to it by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8Wa7N31mP9Va"
   },
   "outputs": [],
   "source": [
    "lif1 = snn.Leaky(beta=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EF70Xi1RX6w"
   },
   "source": [
    "If you would like to explore how this neuron behaves, then refer to [Tutorial 3](https://snntorch.readthedocs.io/en/latest/tutorials/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxl1UYSCRzzl"
   },
   "source": [
    "#3. Backprop Through Time\n",
    "Equation $(4)$ only calculates the gradient for one single time step (referred to as the *immediate influence* in the figure below), but the backpropagation through time (BPTT) algorithm calculates the gradient from the loss to *all* descendants and sums them together.\n",
    "\n",
    "The weight $W$ is applied at every time step, and so imagine a loss is also calculated at every time step. The influence of the weight on present and historical losses must be summed together to define the global gradient:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial W}=\\sum_t \\frac{\\partial\\mathcal{L}[t]}{\\partial W} =\n",
    "\\sum_t \\sum_{s\\leq t} \\frac{\\partial\\mathcal{L}[t]}{\\partial W[s]}\\frac{\\partial W[s]}{\\partial W} \\tag{5} $$\n",
    "\n",
    "The point of $(5)$ is to ensure causality: by constraining $s\\leq t$, we only account for the contribution of immediate and prior influences of $W$ on the loss. A recurrent system constrains the weight to be shared across all steps: $W[0]=W[1] =~... ~ = W$. Therefore, a change in $W[s]$ will have the same effect on all $W$, which implies that $\\partial W[s]/\\partial W=1$:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial W}=\n",
    "\\sum_t \\sum_{s\\leq t} \\frac{\\partial\\mathcal{L}[t]}{\\partial W[s]} \\tag{6} $$\n",
    "\n",
    "As an example, isolate the prior influence due to $s = t-1$ *only*; this means the backward pass must track back in time by one step. The influence of $W[t-1]$ on the loss can be written as:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}[t]}{\\partial W[t-1]} =\n",
    "\\frac{\\partial \\mathcal{L}[t]}{\\partial S[t]}\n",
    "\\underbrace{\\frac{\\partial \\tilde{S}[t]}{\\partial U[t]}}_{Eq.~(5)}\n",
    "\\underbrace{\\frac{\\partial U[t]}{\\partial U[t-1]}}_\\beta\n",
    "\\underbrace{\\frac{\\partial U[t-1]}{\\partial I[t-1]}}_1\n",
    "\\underbrace{\\frac{\\partial I[t-1]}{\\partial W[t-1]}}_{X[t-1]} \\tag{7}$$\n",
    "\n",
    "We have already dealt with all of these terms from $(4)$, except for $\\partial U[t]/\\partial U[t-1]$. From $(1)$, this temporal derivative term simply evaluates to $\\beta$. So if we really wanted to, we now know enough to painstakingly calculate the derivative of every weight at every time step by hand, and it'd look something like this for a single neuron:\n",
    "\n",
    "<center>\n",
    "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial5/bptt.png?raw=true' width=\"600\">\n",
    "</center>\n",
    "\n",
    "But thankfully, PyTorch's autodiff takes care of that in the background for us.  \n",
    "\n",
    "*Note: The reset mechanism has been omitted from the above figure. In snnTorch, reset is included in the forward-pass, but detached from the backward pass.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_42-CbsZ1FM"
   },
   "source": [
    "# 4. Setting up the Loss / Output Decoding\n",
    "In a conventional, non-spiking neural network, a supervised, multi-class classification problem takes the neuron with the highest activation and treats that as the predicted class.\n",
    "\n",
    "In a spiking neural net, there are several options to interpreting the output spikes. The most common approaches are:\n",
    "* **Rate coding:** Take the neuron with the highest firing rate (or spike count) as the predicted class\n",
    "* **Latency coding:** Take the neuron that fires *first* as the predicted class\n",
    "\n",
    "This might feel familiar to [Tutorial 1 on neural encoding](https://snntorch.readthedocs.io/en/latest/tutorials/index.html). The difference is that, here, we are interpreting (decoding) the output spikes, rather than encoding/converting raw input data into spikes.\n",
    "\n",
    "Let's focus on a rate code. When input data is passed to the network, we want the correct neuron class to emit the most spikes over the course of the simulation run. This then corresponds to the highest average firing frequency. One way to achieve this is to increase the membrane potential of the correct class to $U>U_{\\rm thr}$, and that of incorrect classes to $U<U_{\\rm thr}$. Applying the target to $U$ serves as a proxy for modulating spiking behavior from $S$.\n",
    "\n",
    "This can be implemented by taking the softmax of the membrane potential for output neurons, where $C$ is the number of output classes:\n",
    "\n",
    "$$p_i[t] = \\frac{e^{U_i[t]}}{\\sum_{j=0}^{C}e^{U_j[t]}} \\tag{8}$$\n",
    "\n",
    "The cross-entropy between $p_i$ and the target $y_i \\in \\{0,1\\}^C$, which is a one-hot target vector, is obtained using:\n",
    "\n",
    "$$\\mathcal{L}_{CE}[t] = -\\sum_{i=0}^Cy_i{\\rm log}(p_i[t]) \\tag{9}$$\n",
    "\n",
    "The practical effect is that the membrane potential of the correct class is encouraged to increase while those of incorrect classes are reduced. In effect, this means the correct class is encouraged to fire at all time steps, while incorrect classes are suppressed at all steps. This may not be the most efficient implementation of an SNN, but it is among the simplest.\n",
    "\n",
    "This target is applied at every time step of the simulation, thus also generating a loss at every step. These losses are then summed together at the end of the simulation:\n",
    "\n",
    "$$\\mathcal{L}_{CE} = \\sum_t\\mathcal{L}_{CE}[t] \\tag{10}$$\n",
    "\n",
    "This is just one of many possible ways to apply a loss function to a spiking neural network. A variety of approaches are available to use in snnTorch (in the module `snn.functional`), and will be the subject of a future tutorial.\n",
    "\n",
    "With all of the background theory having been taken care of, let’s finally dive into\n",
    "training a fully-connected spiking neural net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqJdfllYbc16"
   },
   "source": [
    "# 5. Setting up the Static MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lI0GbgLgpkos",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataloader arguments\n",
    "batch_size = 16\n",
    "data_path='/tmp/data/mnist'\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2fhRixcspkot",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAM_dP887uTq"
   },
   "source": [
    "If the above code blocks throws an error, e.g. the MNIST servers are down, then uncomment the following code instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4jyJVqUNdXDo"
   },
   "outputs": [],
   "source": [
    "# # temporary dataloader if MNIST service is unavailable\n",
    "# !wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "# !tar -zxvf MNIST.tar.gz\n",
    "\n",
    "# mnist_train = datasets.MNIST(root = './', train=True, download=True, transform=transform)\n",
    "# mnist_test = datasets.MNIST(root = './', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aEtCbO6upkou",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhFyzySNeT_e"
   },
   "source": [
    "# 6. Define the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Lud3kywn55fj"
   },
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "num_inputs = 28*28\n",
    "num_hidden = 1000\n",
    "num_outputs = 10\n",
    "\n",
    "# Temporal Dynamics\n",
    "num_steps = 25\n",
    "beta = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-uquHLLmpkox",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    "\n",
    "# Load the network onto CUDA if available\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0fHcAKfrav6"
   },
   "source": [
    "The code in the `forward()` function will only be called once the input argument `x` is explicitly passed into `net`.\n",
    "\n",
    "* `fc1` applies a linear transformation to all input pixels from the MNIST dataset;\n",
    "* `lif1` integrates the weighted input over time, emitting a spike if the threshold condition is met;\n",
    "* `fc2` applies a linear transformation to the output spikes of `lif1`;\n",
    "* `lif2` is another spiking neuron layer, integrating the weighted spikes over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a7MdORCtIx4"
   },
   "source": [
    "# 7. Training the SNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D-fhT3Q7nXM"
   },
   "source": [
    "## 7.1 Accuracy Metric\n",
    "Below is a function that takes a batch of data, counts up all the spikes from each neuron (i.e., a rate code over the simulation time), and compares the index of the highest count with the actual target. If they match, then the network correctly predicted the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-IxcnBAxpkoy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pass data into the network, sum the spikes over time\n",
    "# and compare the neuron with the highest number of spikes\n",
    "# with the target\n",
    "\n",
    "def print_batch_accuracy(data, targets, train=False):\n",
    "    output, _ = net(data.view(batch_size, -1))\n",
    "    _, idx = output.sum(dim=0).max(1)\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "\n",
    "    if train:\n",
    "        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "\n",
    "def train_printer(\n",
    "    data, targets, epoch,\n",
    "    counter, iter_counter,\n",
    "        loss_hist, test_loss_hist, test_data, test_targets):\n",
    "    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
    "    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
    "    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
    "    print_batch_accuracy(data, targets, train=True)\n",
    "    print_batch_accuracy(test_data, test_targets, train=False)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woJSGSx68tsd"
   },
   "source": [
    "## 7.2 Loss Definition\n",
    "The `nn.CrossEntropyLoss` function in PyTorch automatically handles taking the softmax of the output layer as well as generating a loss at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iqdVyjCNtdlp"
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1fPgSoO9Jgb"
   },
   "source": [
    "## 7.3 Optimizer\n",
    "Adam is a robust optimizer that performs well on recurrent networks, so let's use that with a learning rate of $5\\times10^{-4}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "l62ZR51s9Lxg"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiqAVKzVbfPn"
   },
   "source": [
    "## 7.4 One Iteration of Training\n",
    "Take the first batch of data and load it onto CUDA if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Hv1q2-Mt9kVi"
   },
   "outputs": [],
   "source": [
    "data, targets = next(iter(train_loader))\n",
    "data = data.to(device)\n",
    "targets = targets.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFahTbAv-Vtt"
   },
   "source": [
    "Flatten the input data to a vector of size $784$ and pass it into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lltqTEXE92V-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 16, 10])\n"
     ]
    }
   ],
   "source": [
    "spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
    "print(mem_rec.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wd_qv6xD-lCb"
   },
   "source": [
    "The recording of the membrane potential is taken across:\n",
    "* 25 time steps\n",
    "* 128 samples of data\n",
    "* 10 output neurons\n",
    "\n",
    "We wish to calculate the loss at every time step, and sum these up together, as per Equation $(10)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nsnH8y5G-D-z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 61.218\n"
     ]
    }
   ],
   "source": [
    "# initialize the total loss value\n",
    "loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "\n",
    "# sum loss at every step\n",
    "for step in range(num_steps):\n",
    "  loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "print(f\"Training loss: {loss_val.item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4r0sKMV_4ri"
   },
   "source": [
    "The loss is quite large, because it is summed over 25 time steps. The accuracy is also bad (it should be roughly around 10%) as the network is untrained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qetPvz7mAArd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for a single minibatch: 12.50%\n"
     ]
    }
   ],
   "source": [
    "print_batch_accuracy(data, targets, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUcR0GcUAtPn"
   },
   "source": [
    "A single weight update is applied to the network as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WxyBhsmlAsWM"
   },
   "outputs": [],
   "source": [
    "# clear previously stored gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# calculate the gradients\n",
    "loss_val.backward()\n",
    "\n",
    "# weight update\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubyude8eA5p9"
   },
   "source": [
    "Now, re-run the loss calculation and accuracy after a single iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "l4ZquRR9A9He"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 43.680\n",
      "Train set accuracy for a single minibatch: 81.25%\n"
     ]
    }
   ],
   "source": [
    "# calculate new network outputs using the same data\n",
    "spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
    "\n",
    "# initialize the total loss value\n",
    "loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "\n",
    "# sum loss at every step\n",
    "for step in range(num_steps):\n",
    "  loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "print(f\"Training loss: {loss_val.item():.3f}\")\n",
    "print_batch_accuracy(data, targets, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbNPCNTSBaW3"
   },
   "source": [
    "After only one iteration, the loss should have decreased and accuracy should have increased. Note how membrane potential is used to calculate the cross entropy\n",
    "loss, and spike count is used for the measure of accuracy. It is also possible to use the spike count in the loss ([see Tutorial 6](https://snntorch.readthedocs.io/en/latest/tutorials/index.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVgKDes8BiXq"
   },
   "source": [
    "## 7.5 Training Loop\n",
    "\n",
    "Let's combine everything into a training loop. We will train for one epoch (though feel free to increase `num_epochs`), exposing our network to each sample of data once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "LMZMxEV8dcTC",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0\n",
      "Train Set Loss: 61.62\n",
      "Test Set Loss: 49.83\n",
      "Train set accuracy for a single minibatch: 68.75%\n",
      "Test set accuracy for a single minibatch: 43.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 50\n",
      "Train Set Loss: 11.35\n",
      "Test Set Loss: 11.02\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 87.50%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 100\n",
      "Train Set Loss: 22.32\n",
      "Test Set Loss: 19.31\n",
      "Train set accuracy for a single minibatch: 75.00%\n",
      "Test set accuracy for a single minibatch: 81.25%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 150\n",
      "Train Set Loss: 24.64\n",
      "Test Set Loss: 8.92\n",
      "Train set accuracy for a single minibatch: 81.25%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 200\n",
      "Train Set Loss: 7.56\n",
      "Test Set Loss: 12.23\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 81.25%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 250\n",
      "Train Set Loss: 6.79\n",
      "Test Set Loss: 5.05\n",
      "Train set accuracy for a single minibatch: 87.50%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 300\n",
      "Train Set Loss: 7.73\n",
      "Test Set Loss: 17.32\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 81.25%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 350\n",
      "Train Set Loss: 12.39\n",
      "Test Set Loss: 6.47\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 400\n",
      "Train Set Loss: 6.65\n",
      "Test Set Loss: 18.46\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 87.50%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 450\n",
      "Train Set Loss: 3.85\n",
      "Test Set Loss: 12.76\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 87.50%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 500\n",
      "Train Set Loss: 19.95\n",
      "Test Set Loss: 21.06\n",
      "Train set accuracy for a single minibatch: 81.25%\n",
      "Test set accuracy for a single minibatch: 81.25%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 550\n",
      "Train Set Loss: 3.68\n",
      "Test Set Loss: 8.73\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 600\n",
      "Train Set Loss: 7.66\n",
      "Test Set Loss: 6.14\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 650\n",
      "Train Set Loss: 7.13\n",
      "Test Set Loss: 30.86\n",
      "Train set accuracy for a single minibatch: 87.50%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 700\n",
      "Train Set Loss: 6.50\n",
      "Test Set Loss: 11.32\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 750\n",
      "Train Set Loss: 14.46\n",
      "Test Set Loss: 9.64\n",
      "Train set accuracy for a single minibatch: 81.25%\n",
      "Test set accuracy for a single minibatch: 87.50%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 800\n",
      "Train Set Loss: 6.88\n",
      "Test Set Loss: 3.34\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 850\n",
      "Train Set Loss: 4.95\n",
      "Test Set Loss: 3.00\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 900\n",
      "Train Set Loss: 10.17\n",
      "Test Set Loss: 3.06\n",
      "Train set accuracy for a single minibatch: 87.50%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 950\n",
      "Train Set Loss: 6.03\n",
      "Test Set Loss: 9.33\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1000\n",
      "Train Set Loss: 4.92\n",
      "Test Set Loss: 3.15\n",
      "Train set accuracy for a single minibatch: 81.25%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1050\n",
      "Train Set Loss: 6.75\n",
      "Test Set Loss: 3.21\n",
      "Train set accuracy for a single minibatch: 87.50%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1100\n",
      "Train Set Loss: 7.10\n",
      "Test Set Loss: 8.17\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1150\n",
      "Train Set Loss: 5.81\n",
      "Test Set Loss: 5.55\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1200\n",
      "Train Set Loss: 3.78\n",
      "Test Set Loss: 3.59\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1250\n",
      "Train Set Loss: 8.25\n",
      "Test Set Loss: 4.90\n",
      "Train set accuracy for a single minibatch: 87.50%\n",
      "Test set accuracy for a single minibatch: 87.50%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1300\n",
      "Train Set Loss: 7.69\n",
      "Test Set Loss: 8.45\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1350\n",
      "Train Set Loss: 3.55\n",
      "Test Set Loss: 3.62\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 81.25%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1400\n",
      "Train Set Loss: 4.62\n",
      "Test Set Loss: 13.56\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 75.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1450\n",
      "Train Set Loss: 3.77\n",
      "Test Set Loss: 2.41\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1500\n",
      "Train Set Loss: 5.24\n",
      "Test Set Loss: 7.03\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1550\n",
      "Train Set Loss: 11.77\n",
      "Test Set Loss: 2.84\n",
      "Train set accuracy for a single minibatch: 87.50%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1600\n",
      "Train Set Loss: 8.19\n",
      "Test Set Loss: 4.66\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1650\n",
      "Train Set Loss: 7.58\n",
      "Test Set Loss: 2.71\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1700\n",
      "Train Set Loss: 3.29\n",
      "Test Set Loss: 38.17\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 87.50%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1750\n",
      "Train Set Loss: 5.26\n",
      "Test Set Loss: 3.11\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1800\n",
      "Train Set Loss: 9.07\n",
      "Test Set Loss: 2.95\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1850\n",
      "Train Set Loss: 5.46\n",
      "Test Set Loss: 8.34\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1900\n",
      "Train Set Loss: 13.11\n",
      "Test Set Loss: 4.44\n",
      "Train set accuracy for a single minibatch: 87.50%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 1950\n",
      "Train Set Loss: 2.03\n",
      "Test Set Loss: 6.50\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2000\n",
      "Train Set Loss: 5.78\n",
      "Test Set Loss: 3.09\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2050\n",
      "Train Set Loss: 4.70\n",
      "Test Set Loss: 5.22\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2100\n",
      "Train Set Loss: 4.81\n",
      "Test Set Loss: 3.61\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2150\n",
      "Train Set Loss: 2.77\n",
      "Test Set Loss: 6.88\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2200\n",
      "Train Set Loss: 6.58\n",
      "Test Set Loss: 1.69\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2250\n",
      "Train Set Loss: 6.31\n",
      "Test Set Loss: 2.91\n",
      "Train set accuracy for a single minibatch: 87.50%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2300\n",
      "Train Set Loss: 16.69\n",
      "Test Set Loss: 4.59\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2350\n",
      "Train Set Loss: 5.84\n",
      "Test Set Loss: 4.68\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2400\n",
      "Train Set Loss: 2.98\n",
      "Test Set Loss: 3.36\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2450\n",
      "Train Set Loss: 4.95\n",
      "Test Set Loss: 2.62\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2500\n",
      "Train Set Loss: 2.76\n",
      "Test Set Loss: 3.58\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2550\n",
      "Train Set Loss: 5.42\n",
      "Test Set Loss: 2.19\n",
      "Train set accuracy for a single minibatch: 87.50%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2600\n",
      "Train Set Loss: 2.33\n",
      "Test Set Loss: 3.78\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2650\n",
      "Train Set Loss: 3.49\n",
      "Test Set Loss: 2.22\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2700\n",
      "Train Set Loss: 3.58\n",
      "Test Set Loss: 3.73\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2750\n",
      "Train Set Loss: 2.45\n",
      "Test Set Loss: 3.27\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2800\n",
      "Train Set Loss: 9.39\n",
      "Test Set Loss: 2.42\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2850\n",
      "Train Set Loss: 8.00\n",
      "Test Set Loss: 2.04\n",
      "Train set accuracy for a single minibatch: 87.50%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2900\n",
      "Train Set Loss: 2.24\n",
      "Test Set Loss: 6.84\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 87.50%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 2950\n",
      "Train Set Loss: 2.64\n",
      "Test Set Loss: 4.45\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3000\n",
      "Train Set Loss: 14.52\n",
      "Test Set Loss: 4.44\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3050\n",
      "Train Set Loss: 1.44\n",
      "Test Set Loss: 6.60\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3100\n",
      "Train Set Loss: 1.71\n",
      "Test Set Loss: 5.84\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3150\n",
      "Train Set Loss: 8.74\n",
      "Test Set Loss: 2.91\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3200\n",
      "Train Set Loss: 4.22\n",
      "Test Set Loss: 1.51\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3250\n",
      "Train Set Loss: 1.68\n",
      "Test Set Loss: 5.14\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3300\n",
      "Train Set Loss: 2.19\n",
      "Test Set Loss: 12.82\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3350\n",
      "Train Set Loss: 1.31\n",
      "Test Set Loss: 2.81\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3400\n",
      "Train Set Loss: 1.35\n",
      "Test Set Loss: 5.09\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3450\n",
      "Train Set Loss: 3.07\n",
      "Test Set Loss: 4.32\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3500\n",
      "Train Set Loss: 4.52\n",
      "Test Set Loss: 3.31\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3550\n",
      "Train Set Loss: 2.69\n",
      "Test Set Loss: 7.15\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 93.75%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3600\n",
      "Train Set Loss: 3.22\n",
      "Test Set Loss: 1.57\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3650\n",
      "Train Set Loss: 2.76\n",
      "Test Set Loss: 2.68\n",
      "Train set accuracy for a single minibatch: 100.00%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 3700\n",
      "Train Set Loss: 2.79\n",
      "Test Set Loss: 2.51\n",
      "Train set accuracy for a single minibatch: 93.75%\n",
      "Test set accuracy for a single minibatch: 100.00%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    iter_counter = 0\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    # Minibatch training loop\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "        for step in range(num_steps):\n",
    "            loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Test set\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            test_data, test_targets = next(iter(test_loader))\n",
    "            test_data = test_data.to(device)\n",
    "            test_targets = test_targets.to(device)\n",
    "\n",
    "            # Test set forward pass\n",
    "            test_spk, test_mem = net(test_data.view(batch_size, -1))\n",
    "\n",
    "            # Test set loss\n",
    "            test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
    "            for step in range(num_steps):\n",
    "                test_loss += loss(test_mem[step], test_targets)\n",
    "            test_loss_hist.append(test_loss.item())\n",
    "\n",
    "            # Print train/test loss/accuracy\n",
    "            if counter % 50 == 0:\n",
    "                train_printer(\n",
    "                    data, targets, epoch,\n",
    "                    counter, iter_counter,\n",
    "                    loss_hist, test_loss_hist,\n",
    "                    test_data, test_targets)\n",
    "            counter += 1\n",
    "            iter_counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Taf6WZLojHTz"
   },
   "source": [
    "If this was your first time training an SNN, then congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "HxU7P7xFpko3",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 8. Results\n",
    "## 8.1 Plot Training/Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_Pk_EScnpkpj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Loss\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "plt.plot(loss_hist)\n",
    "plt.plot(test_loss_hist)\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.legend([\"Train Loss\", \"Test Loss\"])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['fc1.weight', 'fc1.bias', 'lif1.threshold', 'lif1.graded_spikes_factor', 'lif1.reset_mechanism_val', 'lif1.beta', 'fc2.weight', 'fc2.bias', 'lif2.threshold', 'lif2.graded_spikes_factor', 'lif2.reset_mechanism_val', 'lif2.beta'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2023, device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()[\"fc1.weight\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2435, device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()[\"fc1.weight\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_targets = next(iter(test_loader))\n",
    "test_data = test_data.to(device)\n",
    "test_targets = test_targets.to(device)\n",
    "\n",
    "# Test set forward pass\n",
    "test_spk, test_mem = net(test_data.view(batch_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-76.0454, device='cuda:0', grad_fn=<MinBackward1>),\n",
       " tensor(25.2054, device='cuda:0', grad_fn=<MaxBackward1>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mem.min(), test_mem.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-Gd84OAl1rB"
   },
   "source": [
    "The loss curves are noisy because the losses are tracked at every iteration, rather than averaging across multiple iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "Z3f0vBnBpkpk",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 8.2 Test Set Accuracy\n",
    "This function iterates over all minibatches to obtain a measure of accuracy over the full 10,000 samples in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "F5Rb4xHGndQh"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m test_spk, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# calculate total accuracy\u001b[39;00m\n\u001b[1;32m     17\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m test_spk\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/snn-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/snn-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m spk1, mem1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlif1(cur1, mem1)\n\u001b[1;32m     25\u001b[0m cur2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(spk1)\n\u001b[0;32m---> 26\u001b[0m spk2, mem2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlif2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m spk2_rec\u001b[38;5;241m.\u001b[39mappend(spk2)\n\u001b[1;32m     28\u001b[0m mem2_rec\u001b[38;5;241m.\u001b[39mappend(mem2)\n",
      "File \u001b[0;32m~/mambaforge/envs/snn-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/snn-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/snn-gpu/lib/python3.10/site-packages/snntorch/_neurons/leaky.py:177\u001b[0m, in \u001b[0;36mLeaky.forward\u001b[0;34m(self, input_, mem)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_hidden:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem_reset(mem)\n\u001b[0;32m--> 177\u001b[0m     mem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_state_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_quant:\n\u001b[1;32m    180\u001b[0m         mem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_quant(mem)\n",
      "File \u001b[0;32m~/mambaforge/envs/snn-gpu/lib/python3.10/site-packages/snntorch/_neurons/leaky.py:216\u001b[0m, in \u001b[0;36mLeaky._build_state_function\u001b[0;34m(self, input_, mem)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_state_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_, mem):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_mechanism_val \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# reset by subtraction\u001b[39;00m\n\u001b[1;32m    215\u001b[0m         state_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_state_function(\n\u001b[0;32m--> 216\u001b[0m             input_, mem \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreshold\u001b[49m\n\u001b[1;32m    217\u001b[0m         )\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_mechanism_val \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# reset to zero\u001b[39;00m\n\u001b[1;32m    219\u001b[0m         state_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_state_function(\n\u001b[1;32m    220\u001b[0m             input_, mem\n\u001b[1;32m    221\u001b[0m         ) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_state_function(input_, mem)\n",
      "File \u001b[0;32m~/mambaforge/envs/snn-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1682\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1682\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1683\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1684\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "# drop_last switched to False to keep all samples\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "  net.eval()\n",
    "  for data, targets in test_loader:\n",
    "    data = data.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # forward pass\n",
    "    test_spk, _ = net(data.view(data.size(0), -1))\n",
    "\n",
    "    # calculate total accuracy\n",
    "    _, predicted = test_spk.sum(dim=0).max(1)\n",
    "    total += targets.size(0)\n",
    "    correct += (predicted == targets).sum().item()\n",
    "\n",
    "print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
    "print(f\"Test Set Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "TBIXau4Zpkpl",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Voila! That's it for static MNIST. Feel free to tweak the network parameters, hyperparameters, decay rate, using a learning rate scheduler etc. to see if you can improve the network performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0dAgWUt2o6E"
   },
   "source": [
    "# Conclusion\n",
    "Now you know how to construct and train a fully-connected network on a static dataset. The spiking neurons can also be adapted to other layer types, including convolutions and skip connections. Armed with this knowledge, you should now be able to build many different types of SNNs. [In the next tutorial](https://snntorch.readthedocs.io/en/latest/tutorials/index.html), you will learn how to train a spiking convolutional network, and simplify the amount of code required using the `snn.backprop` module.\n",
    "\n",
    "Also, a special thanks to Bugra Kaytanli for providing valuable feedback on the tutorial.\n",
    "\n",
    "If you like this project, please consider starring ⭐ the repo on GitHub as it is the easiest and best way to support it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LuBFFYCVdGI"
   },
   "source": [
    "# Additional Resources\n",
    "\n",
    "* [Check out the snnTorch GitHub project here.](https://github.com/jeshraghian/snntorch)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "snntorch_tutorial_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
